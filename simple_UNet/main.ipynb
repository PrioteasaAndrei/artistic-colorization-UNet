{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src/\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # It\\'s not working!\\n\\nfrom datasets import load_dataset\\nfrom torch.utils.data import Dataset, DataLoader\\nfrom PIL import Image\\nfrom dotenv import load_dotenv\\n\\nTRAIN_SIZE = 100\\nVAL_SIZE = 10\\nBATCH_SIZE = 8\\n\\ntorch.manual_seed(1)\\nload_dotenv()\\n\\ntransform_train = torchvision.transforms.Compose([\\n    torchvision.transforms.Resize((256, 256), interpolation=Image.BILINEAR),\\n    torchvision.transforms.ToTensor() \\n])\\ntransform_validation = torchvision.transforms.Compose([\\n    torchvision.transforms.Resize((256, 256), interpolation=Image.BILINEAR),\\n    torchvision.transforms.ToTensor(),\\n])\\n\\ndef check_range(tensor):\\n    return (tensor.min() >= 0) and (tensor.max() <= 1)\\n\\ndef prepare_dataset(train_size=10,test_size=10,batch_size=8):\\n    login_token = os.getenv(\\'HUGGING_FACE_TOKEN\\')\\n    dataset_train = load_dataset(\"imagenet-1k\",split=\\'train\\',use_auth_token=login_token,streaming=True)\\n    dataset_validation = load_dataset(\"imagenet-1k\",split=\\'test\\',use_auth_token=login_token,streaming=True)\\n    \\n    # map resize transformation before take \\n    transformed_train = dataset_train.map(lambda x: {\\'image\\': transform_train(x[\\'image\\']), \\'grayscale_image\\': transform_validation(x[\\'image\\']),\\'label\\': torch.tensor(x[\\'label\\'])})\\n    transformed_test = dataset_validation.map(lambda x: {\\'image\\': transform_validation(x[\\'image\\']),\\'label\\': torch.tensor(x[\\'label\\'])})\\n    \\n    # shuffle train dataset\\n    transformed_train = transformed_train.shuffle()\\n \\n    print(\"Dataset loaded successfully\")\\n    return transformed_train.take(train_size),transformed_test.take(test_size)\\n\\nclass RecreationDataset(Dataset):\\n    def __init__(self, data):\\n        self.data = data\\n\\n    def __len__(self):\\n        return len(self.data)\\n\\n    def __getitem__(self, idx):\\n        image = self.data[idx][\\'image\\']\\n        return {\\'image\\': image}\\n        \\ndef prepare_dataloader(train_data,test_data,batch_size=4):\\n    \\n    # prepare data loader\\n    list_train_data = list(train_data)\\n    # filter out 1 channel images\\n    train_data = list(filter(lambda x: x[\\'image\\'].shape[0] == 3, list_train_data))\\n\\n    colorization_dataset_train = RecreationDataset(train_data)\\n    colorization_dataloader_train = DataLoader(colorization_dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\\n\\n    colorization_dataset_validation = RecreationDataset(list(test_data), test=True)\\n    colorization_dataloader_validation = DataLoader(colorization_dataset_validation, batch_size=batch_size, shuffle=False, num_workers=4)\\n    \\n    print(\"Data loader prepared successfully\")\\n    return colorization_dataloader_train, colorization_dataloader_validation\\n\\ntrain_data, validation_data = prepare_dataset(train_size=TRAIN_SIZE, test_size=VAL_SIZE, batch_size=BATCH_SIZE)\\ntrain_loader, validation_loader = prepare_dataloader(train_data, validation_data, batch_size=BATCH_SIZE)\\n '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # It's not working!\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "TRAIN_SIZE = 100\n",
    "VAL_SIZE = 10\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "torch.manual_seed(1)\n",
    "load_dotenv()\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256, 256), interpolation=Image.BILINEAR),\n",
    "    torchvision.transforms.ToTensor() \n",
    "])\n",
    "transform_validation = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256, 256), interpolation=Image.BILINEAR),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def check_range(tensor):\n",
    "    return (tensor.min() >= 0) and (tensor.max() <= 1)\n",
    "\n",
    "def prepare_dataset(train_size=10,test_size=10,batch_size=8):\n",
    "    login_token = os.getenv('HUGGING_FACE_TOKEN')\n",
    "    dataset_train = load_dataset(\"imagenet-1k\",split='train',use_auth_token=login_token,streaming=True)\n",
    "    dataset_validation = load_dataset(\"imagenet-1k\",split='test',use_auth_token=login_token,streaming=True)\n",
    "    \n",
    "    # map resize transformation before take \n",
    "    transformed_train = dataset_train.map(lambda x: {'image': transform_train(x['image']), 'grayscale_image': transform_validation(x['image']),'label': torch.tensor(x['label'])})\n",
    "    transformed_test = dataset_validation.map(lambda x: {'image': transform_validation(x['image']),'label': torch.tensor(x['label'])})\n",
    "    \n",
    "    # shuffle train dataset\n",
    "    transformed_train = transformed_train.shuffle()\n",
    " \n",
    "    print(\"Dataset loaded successfully\")\n",
    "    return transformed_train.take(train_size),transformed_test.take(test_size)\n",
    "\n",
    "class RecreationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]['image']\n",
    "        return {'image': image}\n",
    "        \n",
    "def prepare_dataloader(train_data,test_data,batch_size=4):\n",
    "    \n",
    "    # prepare data loader\n",
    "    list_train_data = list(train_data)\n",
    "    # filter out 1 channel images\n",
    "    train_data = list(filter(lambda x: x['image'].shape[0] == 3, list_train_data))\n",
    "\n",
    "    colorization_dataset_train = RecreationDataset(train_data)\n",
    "    colorization_dataloader_train = DataLoader(colorization_dataset_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    colorization_dataset_validation = RecreationDataset(list(test_data), test=True)\n",
    "    colorization_dataloader_validation = DataLoader(colorization_dataset_validation, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    print(\"Data loader prepared successfully\")\n",
    "    return colorization_dataloader_train, colorization_dataloader_validation\n",
    "\n",
    "train_data, validation_data = prepare_dataset(train_size=TRAIN_SIZE, test_size=VAL_SIZE, batch_size=BATCH_SIZE)\n",
    "train_loader, validation_loader = prepare_dataloader(train_data, validation_data, batch_size=BATCH_SIZE)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Data loader prepared successfully\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 100\n",
    "VAL_SIZE = 10\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "from dataset import prepare_dataset, prepare_dataloader\n",
    "\n",
    "train_data, validation_data = prepare_dataset(train_size=TRAIN_SIZE, test_size=VAL_SIZE, batch_size=BATCH_SIZE)\n",
    "train_loader, validation_loader = prepare_dataloader(train_data, validation_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_C = 3, out_C=3):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_C, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.maxpool_1to2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.maxpool_2to3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        self.maxpool_3to4 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "        self.maxpool_4to5 = nn.MaxPool2d(2, 2)\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512),\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.conv_transpose_5to6 = nn.ConvTranspose2d(512, 512, 4, stride=2, padding=1)\n",
    "        self.conv1d_fusing_5to6 = nn.Conv2d(1024, 512, 1)\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "        self.conv_transpose_6to7 = nn.ConvTranspose2d(256, 256, 4, stride=2, padding=1)\n",
    "        self.conv1d_fusing_6to7 = nn.Conv2d(512, 256, 1)\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.conv_transpose_7to8 = nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1)\n",
    "        self.conv1d_fusing_7to8 = nn.Conv2d(256, 128, 1)\n",
    "        self.conv8 = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.conv_transpose8to9 = nn.ConvTranspose2d(64, 64, 4, stride=2, padding=1)\n",
    "        self.conv1d_fusing_8to9 = nn.Conv2d(128, 64, 1)\n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),      # Simmetry broken here: keeps being 64 (from paper)\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.conv10 = nn.Conv2d(64, out_C, 1)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=x.to(device)\n",
    "        # Encoder\n",
    "        conv1 = self.conv1(x)\n",
    "        maxpooled_1to2 = self.maxpool_1to2(conv1)\n",
    "        conv2 = self.conv2(maxpooled_1to2)\n",
    "        maxpooled_2to3 = self.maxpool_2to3(conv2)\n",
    "        conv3 = self.conv3(maxpooled_2to3)\n",
    "        maxpooled_3to4 = self.maxpool_3to4(conv3)\n",
    "        conv4 = self.conv4(maxpooled_3to4)\n",
    "        maxpooled_4to5 = self.maxpool_4to5(conv4)\n",
    "        conv5 = self.conv5(maxpooled_4to5)\n",
    "        \n",
    "        # Decoder\n",
    "        concatenation_5to6 = torch.cat((conv4, self.conv_transpose_5to6(conv5)),1)\n",
    "        skip_fusion_5to6 = self.conv1d_fusing_5to6(concatenation_5to6)\n",
    "        conv6 = self.conv6(skip_fusion_5to6)\n",
    "\n",
    "        concatenation_6to7 = torch.cat((conv3, self.conv_transpose_6to7(conv6)),1)\n",
    "        skip_fusion_6to7 = self.conv1d_fusing_6to7(concatenation_6to7)\n",
    "        conv7 = self.conv7(skip_fusion_6to7)\n",
    "        \n",
    "        concatenation_7to8 = torch.cat((conv2, self.conv_transpose_7to8(conv7)),1)\n",
    "        skip_fusion_7to8 = self.conv1d_fusing_7to8(concatenation_7to8)\n",
    "        conv8 = self.conv8(skip_fusion_7to8)\n",
    "\n",
    "        concatenation_8_to9 = torch.cat((conv1, self.conv_transpose8to9(conv8)),1)\n",
    "        skip_fusion_8to9 = self.conv1d_fusing_8to9(concatenation_8_to9)\n",
    "        conv9 = self.conv9(skip_fusion_8to9)\n",
    "\n",
    "        output = self.conv10(conv9)\n",
    "        return output\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader, epochs=10, lr=0.001, loss_fn=nn.MSELoss(), optimizer=torch.optim.Adam, verbose=True):\n",
    "        self.to(device)\n",
    "        self.train()\n",
    "        optimizer = optimizer(self.parameters(), lr=lr)\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            for i, batch_data in enumerate(train_loader):\n",
    "                image = batch_data['image']\n",
    "                image = image.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                reproduced_image = self(image)\n",
    "                reproduced_image = reproduced_image.to(device)\n",
    "                loss = loss_fn(reproduced_image, image)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if verbose and i % 100 == 0:\n",
    "                    print(f\"Epoch {epoch}, iter {i}: loss = {loss.item()}\")\n",
    "\n",
    "net=UNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0: loss = 0.37226566672325134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:58, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, iter 0: loss = 0.10958989709615707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:36<02:21, 17.68s/it]"
     ]
    }
   ],
   "source": [
    "net.train_model(train_loader=train_loader, val_loader=validation_loader, epochs=10, lr=0.001, loss_fn=nn.MSELoss(), optimizer=torch.optim.Adam, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
