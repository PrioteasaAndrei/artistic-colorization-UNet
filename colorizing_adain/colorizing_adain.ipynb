{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available: False\n",
      "mps is available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "with open(\"cfg.yaml\", \"r\") as file:\n",
    "        cfg = yaml.safe_load(file)\n",
    "\n",
    "sys.path.append(\"src/\")\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"cuda is available: {torch.cuda.is_available()}\")\n",
    "print(f\"mps is available: {torch.backends.mps.is_available()}\")\n",
    "\n",
    "from net import VGG_Encoder, Decoder, Net\n",
    "from train import train\n",
    "from inference_generation import test_transform, style_transfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VGG_Encoder()\n",
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_Encoder(\n",
      "  (relu1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (relu2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "  (relu3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "  (relu4): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "Decoder(\n",
      "  (decode): Sequential(\n",
      "    (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (2): ReLU()\n",
      "    (3): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (12): ReLU()\n",
      "    (13): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (15): ReLU()\n",
      "    (16): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (17): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (19): ReLU()\n",
      "    (20): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (22): ReLU()\n",
      "    (23): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (24): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (25): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (26): ReLU()\n",
      "    (27): ReflectionPad2d((1, 1, 1, 1))\n",
      "    (28): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (enc_1): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (enc_2): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (enc_3): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (enc_4): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decode): Sequential(\n",
      "      (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (2): ReLU()\n",
      "      (3): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (6): ReLU()\n",
      "      (7): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (9): ReLU()\n",
      "      (10): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (12): ReLU()\n",
      "      (13): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (14): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (15): ReLU()\n",
      "      (16): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (17): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (18): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (19): ReLU()\n",
      "      (20): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (21): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (22): ReLU()\n",
      "      (23): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (24): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (25): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (26): ReLU()\n",
      "      (27): ReflectionPad2d((1, 1, 1, 1))\n",
      "      (28): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (mse_loss): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net(encoder, decoder)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "grayscale_image=torch.rand(1,3,256,256)\n",
    "style_reference_image=torch.rand(1,3,256,256)\n",
    "\n",
    "output = net(grayscale_image, style_reference_image)\n",
    "print(output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Using device: mps"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 603/1000 [12:05<08:21,  1.26s/it]"
     ]
    }
   ],
   "source": [
    "train(net,cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0432,  0.0433,  0.0431,  ...,  0.0431,  0.0431,  0.0432],\n",
       "          [ 0.0434,  0.0435,  0.0433,  ...,  0.0432,  0.0432,  0.0432],\n",
       "          [ 0.0432,  0.0433,  0.0432,  ...,  0.0432,  0.0432,  0.0433],\n",
       "          ...,\n",
       "          [ 0.0428,  0.0427,  0.0426,  ...,  0.0434,  0.0432,  0.0438],\n",
       "          [ 0.0428,  0.0426,  0.0425,  ...,  0.0437,  0.0434,  0.0440],\n",
       "          [ 0.0427,  0.0426,  0.0425,  ...,  0.0435,  0.0430,  0.0437]],\n",
       "\n",
       "         [[ 0.0286,  0.0285,  0.0286,  ...,  0.0283,  0.0285,  0.0284],\n",
       "          [ 0.0287,  0.0286,  0.0287,  ...,  0.0284,  0.0285,  0.0285],\n",
       "          [ 0.0285,  0.0284,  0.0286,  ...,  0.0284,  0.0285,  0.0285],\n",
       "          ...,\n",
       "          [ 0.0286,  0.0284,  0.0283,  ...,  0.0268,  0.0269,  0.0270],\n",
       "          [ 0.0285,  0.0284,  0.0283,  ...,  0.0272,  0.0272,  0.0274],\n",
       "          [ 0.0285,  0.0284,  0.0284,  ...,  0.0272,  0.0274,  0.0273]],\n",
       "\n",
       "         [[-0.0103, -0.0103, -0.0103,  ..., -0.0099, -0.0099, -0.0099],\n",
       "          [-0.0100, -0.0101, -0.0101,  ..., -0.0098, -0.0099, -0.0100],\n",
       "          [-0.0100, -0.0101, -0.0101,  ..., -0.0097, -0.0098, -0.0098],\n",
       "          ...,\n",
       "          [-0.0100, -0.0099, -0.0100,  ..., -0.0092, -0.0093, -0.0091],\n",
       "          [-0.0097, -0.0096, -0.0099,  ..., -0.0086, -0.0088, -0.0086],\n",
       "          [-0.0096, -0.0096, -0.0098,  ..., -0.0086, -0.0087, -0.0086]]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This are the image and the style I want to mix\n",
    "# --> Set their path in cfg.yaml\n",
    "input_img=Image.open(\"data/content_dir/brad_pitt.jpg\")\n",
    "display(input_img)\n",
    "style_ref=Image.open(\"data/style_dir/brushstrokes.jpg\")\n",
    "display(style_ref)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "\n",
    "output_dir = Path(cfg[\"output_dir\"])\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Either --content or --contentDir should be given.\n",
    "assert (cfg[\"content\"] or cfg[\"content_dir\"])\n",
    "if cfg[\"content\"]:\n",
    "    content_paths = [Path(cfg[\"content\"])]\n",
    "else:\n",
    "    content_dir = Path(cfg[\"content_dir\"])\n",
    "    content_paths = [f for f in content_dir.glob('*')]\n",
    "\n",
    "# Either --style or --styleDir should be given.\n",
    "assert (cfg[\"style\"] or cfg[\"style_dir\"])\n",
    "if cfg[\"style\"]:\n",
    "    style_paths = cfg[\"style\"].split(',')\n",
    "    if len(style_paths) == 1:\n",
    "        style_paths = [Path(cfg[\"style\"])]\n",
    "    else:\n",
    "        do_interpolation = True\n",
    "        assert (cfg[\"style_interpolation_weights\"] != ''), \\\n",
    "            'Please specify interpolation weights'\n",
    "        weights = [int(i) for i in cfg[\"style_interpolation_weights\"].split(',')]\n",
    "        interpolation_weights = [w / sum(weights) for w in weights]\n",
    "else:\n",
    "    style_dir = Path(cfg[\"style_dir\"])\n",
    "    style_paths = [f for f in style_dir.glob('*')]\n",
    "\n",
    "encoder = VGG_Encoder()\n",
    "decoder = Decoder()\n",
    "\n",
    "decoder.eval()\n",
    "encoder.eval()\n",
    "\n",
    "decoder.load_state_dict(torch.load(cfg[\"decoder\"]))\n",
    "# encoder.load_state_dict(torch.load(args.vgg))\n",
    "#vgg = nn.Sequential(*list(vgg.children())[:31])\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "content_tf = test_transform(cfg[\"content_size\"], cfg[\"crop\"])\n",
    "style_tf = test_transform(cfg[\"style_size\"], cfg[\"crop\"])\n",
    "\n",
    "do_interpolation = False\n",
    "\n",
    "for content_path in content_paths:\n",
    "    # OFF\n",
    "    if do_interpolation:  # one content image, N style image\n",
    "        style = torch.stack([style_tf(Image.open(str(p))) for p in style_paths])\n",
    "        content = content_tf(Image.open(str(content_path))) \\\n",
    "            .unsqueeze(0).expand_as(style)\n",
    "        style = style.to(device)\n",
    "        content = content.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = style_transfer(encoder, decoder, content, style,\n",
    "                                    cfg[\"alpha\"], interpolation_weights)\n",
    "        output = output.cpu()\n",
    "        output_name = output_dir / '{:s}_interpolation{:s}'.format(\n",
    "            content_path.stem, cfg[\"save_ext\"])\n",
    "        torchvision.utils.save_image(output, str(output_name))\n",
    "\n",
    "    # ON\n",
    "    else:  # process one content and one style\n",
    "        for style_path in style_paths:\n",
    "            content = content_tf(Image.open(str(content_path)))\n",
    "            style = style_tf(Image.open(str(style_path)))\n",
    "            #if cfg[\"preserve_color\"]:\n",
    "            #    style = coral(style, content)\n",
    "            style = style.to(device).unsqueeze(0)\n",
    "            content = content.to(device).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                output = style_transfer(encoder, decoder, content, style,\n",
    "                                        cfg[\"alpha\"])\n",
    "            output = output.cpu()\n",
    "            display(output)\n",
    "\n",
    "            output_name = output_dir / '{:s}_stylized_{:s}{:s}'.format(\n",
    "                content_path.stem, style_path.stem, cfg[\"save_ext\"])\n",
    "            torchvision.utils.save_image(output, str(output_name))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
