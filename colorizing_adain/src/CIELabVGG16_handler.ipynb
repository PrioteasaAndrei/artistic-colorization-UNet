{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./../model/LabVGG16_dict.pth\n",
      "0. conv1.0.weight   torch.Size([64, 3, 3, 3])\n",
      "1. conv1.0.bias   torch.Size([64])\n",
      "2. conv1.1.weight   torch.Size([64])\n",
      "3. conv1.1.bias   torch.Size([64])\n",
      "4. conv1.1.running_mean   torch.Size([64])\n",
      "5. conv1.1.running_var   torch.Size([64])\n",
      "6. conv1.1.num_batches_tracked   torch.Size([])\n",
      "7. conv1.3.weight   torch.Size([64, 64, 3, 3])\n",
      "8. conv1.3.bias   torch.Size([64])\n",
      "9. pool1.0.weight   torch.Size([64])\n",
      "10. pool1.0.bias   torch.Size([64])\n",
      "11. pool1.0.running_mean   torch.Size([64])\n",
      "12. pool1.0.running_var   torch.Size([64])\n",
      "13. pool1.0.num_batches_tracked   torch.Size([])\n",
      "14. conv2.0.weight   torch.Size([128, 64, 3, 3])\n",
      "15. conv2.0.bias   torch.Size([128])\n",
      "16. conv2.1.weight   torch.Size([128])\n",
      "17. conv2.1.bias   torch.Size([128])\n",
      "18. conv2.1.running_mean   torch.Size([128])\n",
      "19. conv2.1.running_var   torch.Size([128])\n",
      "20. conv2.1.num_batches_tracked   torch.Size([])\n",
      "21. conv2.3.weight   torch.Size([128, 128, 3, 3])\n",
      "22. conv2.3.bias   torch.Size([128])\n",
      "23. pool2.0.weight   torch.Size([128])\n",
      "24. pool2.0.bias   torch.Size([128])\n",
      "25. pool2.0.running_mean   torch.Size([128])\n",
      "26. pool2.0.running_var   torch.Size([128])\n",
      "27. pool2.0.num_batches_tracked   torch.Size([])\n",
      "28. conv3.0.weight   torch.Size([256, 128, 3, 3])\n",
      "29. conv3.0.bias   torch.Size([256])\n",
      "30. conv3.1.weight   torch.Size([256])\n",
      "31. conv3.1.bias   torch.Size([256])\n",
      "32. conv3.1.running_mean   torch.Size([256])\n",
      "33. conv3.1.running_var   torch.Size([256])\n",
      "34. conv3.1.num_batches_tracked   torch.Size([])\n",
      "35. conv3.3.weight   torch.Size([256, 256, 3, 3])\n",
      "36. conv3.3.bias   torch.Size([256])\n",
      "37. conv3.4.weight   torch.Size([256])\n",
      "38. conv3.4.bias   torch.Size([256])\n",
      "39. conv3.4.running_mean   torch.Size([256])\n",
      "40. conv3.4.running_var   torch.Size([256])\n",
      "41. conv3.4.num_batches_tracked   torch.Size([])\n",
      "42. conv3.6.weight   torch.Size([256, 256, 3, 3])\n",
      "43. conv3.6.bias   torch.Size([256])\n",
      "44. pool3.0.weight   torch.Size([256])\n",
      "45. pool3.0.bias   torch.Size([256])\n",
      "46. pool3.0.running_mean   torch.Size([256])\n",
      "47. pool3.0.running_var   torch.Size([256])\n",
      "48. pool3.0.num_batches_tracked   torch.Size([])\n",
      "49. conv4.0.weight   torch.Size([512, 256, 3, 3])\n",
      "50. conv4.0.bias   torch.Size([512])\n",
      "51. conv4.1.weight   torch.Size([512])\n",
      "52. conv4.1.bias   torch.Size([512])\n",
      "53. conv4.1.running_mean   torch.Size([512])\n",
      "54. conv4.1.running_var   torch.Size([512])\n",
      "55. conv4.1.num_batches_tracked   torch.Size([])\n",
      "56. conv4.3.weight   torch.Size([512, 512, 3, 3])\n",
      "57. conv4.3.bias   torch.Size([512])\n",
      "58. conv4.4.weight   torch.Size([512])\n",
      "59. conv4.4.bias   torch.Size([512])\n",
      "60. conv4.4.running_mean   torch.Size([512])\n",
      "61. conv4.4.running_var   torch.Size([512])\n",
      "62. conv4.4.num_batches_tracked   torch.Size([])\n",
      "63. conv4.6.weight   torch.Size([512, 512, 3, 3])\n",
      "64. conv4.6.bias   torch.Size([512])\n",
      "65. pool4.0.weight   torch.Size([512])\n",
      "66. pool4.0.bias   torch.Size([512])\n",
      "67. pool4.0.running_mean   torch.Size([512])\n",
      "68. pool4.0.running_var   torch.Size([512])\n",
      "69. pool4.0.num_batches_tracked   torch.Size([])\n",
      "70. conv5.0.weight   torch.Size([512, 512, 3, 3])\n",
      "71. conv5.0.bias   torch.Size([512])\n",
      "72. conv5.1.weight   torch.Size([512])\n",
      "73. conv5.1.bias   torch.Size([512])\n",
      "74. conv5.1.running_mean   torch.Size([512])\n",
      "75. conv5.1.running_var   torch.Size([512])\n",
      "76. conv5.1.num_batches_tracked   torch.Size([])\n",
      "77. conv5.3.weight   torch.Size([512, 512, 3, 3])\n",
      "78. conv5.3.bias   torch.Size([512])\n",
      "79. conv5.4.weight   torch.Size([512])\n",
      "80. conv5.4.bias   torch.Size([512])\n",
      "81. conv5.4.running_mean   torch.Size([512])\n",
      "82. conv5.4.running_var   torch.Size([512])\n",
      "83. conv5.4.num_batches_tracked   torch.Size([])\n",
      "84. conv5.6.weight   torch.Size([512, 512, 3, 3])\n",
      "85. conv5.6.bias   torch.Size([512])\n",
      "86. pool5.0.weight   torch.Size([512])\n",
      "87. pool5.0.bias   torch.Size([512])\n",
      "88. pool5.0.running_mean   torch.Size([512])\n",
      "89. pool5.0.running_var   torch.Size([512])\n",
      "90. pool5.0.num_batches_tracked   torch.Size([])\n",
      "91. classifier.0.weight   torch.Size([4096, 25088])\n",
      "92. classifier.0.bias   torch.Size([4096])\n",
      "93. classifier.3.weight   torch.Size([4096, 4096])\n",
      "94. classifier.3.bias   torch.Size([4096])\n",
      "95. classifier.6.weight   torch.Size([1000, 4096])\n",
      "96. classifier.6.bias   torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "\n",
    "name = './../model/LabVGG16.pth'\n",
    "dictname = name[:-4] + '_dict' + name[-4:]\n",
    "print(dictname)\n",
    "\n",
    "net = torch.load(name,map_location=torch.device('cpu'))\n",
    "dictnet = net.state_dict()\n",
    "torch.save(dictnet, dictname)\n",
    "count=0\n",
    "for key in dictnet.keys():\n",
    "    print(\"{}. {}   {}\".format(count,key,dictnet[key].shape))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB VGG16: Trying to import up to pool2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabVGG16(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (pool1): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (pool2): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (pool3): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (pool4): Sequential(\n",
      "    (0): ReLU()\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def l2normalize(v, eps = 1e-12):\n",
    "    return v / (v.norm() + eps)\n",
    "\n",
    "\n",
    "class LabVGG16(nn.Module):\n",
    "    def __init__(self, in_dim = 3, num_classes = 1000):\n",
    "        super(LabVGG16, self).__init__()\n",
    "        # feature extraction part\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_dim, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        )\n",
    "        self.pool1 = nn.Sequential(\n",
    "            nn.ReLU(inplace = False),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        )\n",
    "        self.pool2 = nn.Sequential(\n",
    "            nn.ReLU(inplace = False),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            #nn.ReLU(inplace = True),\n",
    "            #nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        )\n",
    "        self.pool3 = nn.Sequential(\n",
    "            nn.ReLU(inplace = False),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "            #nn.ReLU(inplace = True),\n",
    "            #nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        )\n",
    "        self.pool4 = nn.Sequential(\n",
    "            nn.ReLU(inplace = False),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1),\n",
    "            #nn.ReLU(inplace = True),\n",
    "            #nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        )\n",
    "        \"\"\"\n",
    "        self.pool5 = nn.Sequential(\n",
    "            nn.ReLU(inplace = False),\n",
    "            nn.AdaptiveAvgPool2d((7, 7))\n",
    "        )\n",
    "        # classification part\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        ) \"\"\"\n",
    "\n",
    "    def forward(self, x):                                   # shape: [B, 3, 224, 224]\n",
    "        conv1 = self.conv1(x)                               # shape: [B, 64, 224, 224]\n",
    "        pool1 = self.pool1(conv1)                           # shape: [B, 64, 112, 112]\n",
    "        conv2 = self.conv2(pool1)                           # shape: [B, 128, 112, 112]\n",
    "        pool2 = self.pool2(conv2)                           # shape: [B, 128, 56, 56]\n",
    "        conv3 = self.conv3(pool2)                           # shape: [B, 256, 56, 56]\n",
    "        pool3 = self.pool3(conv3)                           # shape: [B, 256, 28, 28]\n",
    "        conv4 = self.conv4(pool3)                           # shape: [B, 512, 28, 28]\n",
    "        pool4 = self.pool4(conv4)                           # shape: [B, 512, 14, 14]\n",
    "        conv5 = self.conv5(pool4)                           # shape: [B, 512, 14, 14]\n",
    "        \"\"\" pool5 = self.pool5(conv5)                           # shape: [B, 512, 7, 7]\n",
    "        pool5 = pool5.view(x.size(0), -1)                   # shape: [B, 512 * 7 * 7]\n",
    "        x = self.classifier(pool5)                          # shape: [B, 1000]\n",
    "        return x \"\"\"\n",
    "        return conv5\n",
    "\n",
    "net= LabVGG16()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary\n",
    "state_dict = torch.load(\"./../model/LabVGG16_dict.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. conv1.0.weight   torch.Size([64, 3, 3, 3])\n",
      "1. conv1.0.bias   torch.Size([64])\n",
      "2. conv1.1.weight   torch.Size([64])\n",
      "3. conv1.1.bias   torch.Size([64])\n",
      "4. conv1.1.running_mean   torch.Size([64])\n",
      "5. conv1.1.running_var   torch.Size([64])\n",
      "6. conv1.1.num_batches_tracked   torch.Size([])\n",
      "7. conv1.3.weight   torch.Size([64, 64, 3, 3])\n",
      "8. conv1.3.bias   torch.Size([64])\n",
      "9. pool1.0.weight   torch.Size([64])\n",
      "10. pool1.0.bias   torch.Size([64])\n",
      "11. pool1.0.running_mean   torch.Size([64])\n",
      "12. pool1.0.running_var   torch.Size([64])\n",
      "13. pool1.0.num_batches_tracked   torch.Size([])\n",
      "14. conv2.0.weight   torch.Size([128, 64, 3, 3])\n",
      "15. conv2.0.bias   torch.Size([128])\n",
      "16. conv2.1.weight   torch.Size([128])\n",
      "17. conv2.1.bias   torch.Size([128])\n",
      "18. conv2.1.running_mean   torch.Size([128])\n",
      "19. conv2.1.running_var   torch.Size([128])\n",
      "20. conv2.1.num_batches_tracked   torch.Size([])\n",
      "21. conv2.3.weight   torch.Size([128, 128, 3, 3])\n",
      "22. conv2.3.bias   torch.Size([128])\n",
      "23. pool2.0.weight   torch.Size([128])\n",
      "24. pool2.0.bias   torch.Size([128])\n",
      "25. pool2.0.running_mean   torch.Size([128])\n",
      "26. pool2.0.running_var   torch.Size([128])\n",
      "27. pool2.0.num_batches_tracked   torch.Size([])\n",
      "28. conv3.0.weight   torch.Size([256, 128, 3, 3])\n",
      "29. conv3.0.bias   torch.Size([256])\n",
      "30. conv3.1.weight   torch.Size([256])\n",
      "31. conv3.1.bias   torch.Size([256])\n",
      "32. conv3.1.running_mean   torch.Size([256])\n",
      "33. conv3.1.running_var   torch.Size([256])\n",
      "34. conv3.1.num_batches_tracked   torch.Size([])\n",
      "35. conv3.3.weight   torch.Size([256, 256, 3, 3])\n",
      "36. conv3.3.bias   torch.Size([256])\n",
      "37. conv3.4.weight   torch.Size([256])\n",
      "38. conv3.4.bias   torch.Size([256])\n",
      "39. conv3.4.running_mean   torch.Size([256])\n",
      "40. conv3.4.running_var   torch.Size([256])\n",
      "41. conv3.4.num_batches_tracked   torch.Size([])\n",
      "42. conv3.6.weight   torch.Size([256, 256, 3, 3])\n",
      "43. conv3.6.bias   torch.Size([256])\n",
      "44. pool3.0.weight   torch.Size([256])\n",
      "45. pool3.0.bias   torch.Size([256])\n",
      "46. pool3.0.running_mean   torch.Size([256])\n",
      "47. pool3.0.running_var   torch.Size([256])\n",
      "48. pool3.0.num_batches_tracked   torch.Size([])\n",
      "49. conv4.0.weight   torch.Size([512, 256, 3, 3])\n",
      "50. conv4.0.bias   torch.Size([512])\n",
      "51. conv4.1.weight   torch.Size([512])\n",
      "52. conv4.1.bias   torch.Size([512])\n",
      "53. conv4.1.running_mean   torch.Size([512])\n",
      "54. conv4.1.running_var   torch.Size([512])\n",
      "55. conv4.1.num_batches_tracked   torch.Size([])\n",
      "56. conv4.3.weight   torch.Size([512, 512, 3, 3])\n",
      "57. conv4.3.bias   torch.Size([512])\n",
      "58. conv4.4.weight   torch.Size([512])\n",
      "59. conv4.4.bias   torch.Size([512])\n",
      "60. conv4.4.running_mean   torch.Size([512])\n",
      "61. conv4.4.running_var   torch.Size([512])\n",
      "62. conv4.4.num_batches_tracked   torch.Size([])\n",
      "63. conv4.6.weight   torch.Size([512, 512, 3, 3])\n",
      "64. conv4.6.bias   torch.Size([512])\n",
      "65. pool4.0.weight   torch.Size([512])\n",
      "66. pool4.0.bias   torch.Size([512])\n",
      "67. pool4.0.running_mean   torch.Size([512])\n",
      "68. pool4.0.running_var   torch.Size([512])\n",
      "69. pool4.0.num_batches_tracked   torch.Size([])\n",
      "70. conv5.0.weight   torch.Size([512, 512, 3, 3])\n",
      "71. conv5.0.bias   torch.Size([512])\n",
      "72. conv5.1.weight   torch.Size([512])\n",
      "73. conv5.1.bias   torch.Size([512])\n",
      "74. conv5.1.running_mean   torch.Size([512])\n",
      "75. conv5.1.running_var   torch.Size([512])\n",
      "76. conv5.1.num_batches_tracked   torch.Size([])\n",
      "77. conv5.3.weight   torch.Size([512, 512, 3, 3])\n",
      "78. conv5.3.bias   torch.Size([512])\n",
      "79. conv5.4.weight   torch.Size([512])\n",
      "80. conv5.4.bias   torch.Size([512])\n",
      "81. conv5.4.running_mean   torch.Size([512])\n",
      "82. conv5.4.running_var   torch.Size([512])\n",
      "83. conv5.4.num_batches_tracked   torch.Size([])\n",
      "84. conv5.6.weight   torch.Size([512, 512, 3, 3])\n",
      "85. conv5.6.bias   torch.Size([512])\n",
      "86. pool5.0.weight   torch.Size([512])\n",
      "87. pool5.0.bias   torch.Size([512])\n",
      "88. pool5.0.running_mean   torch.Size([512])\n",
      "89. pool5.0.running_var   torch.Size([512])\n",
      "90. pool5.0.num_batches_tracked   torch.Size([])\n",
      "91. classifier.0.weight   torch.Size([4096, 25088])\n",
      "92. classifier.0.bias   torch.Size([4096])\n",
      "93. classifier.3.weight   torch.Size([4096, 4096])\n",
      "94. classifier.3.bias   torch.Size([4096])\n",
      "95. classifier.6.weight   torch.Size([1000, 4096])\n",
      "96. classifier.6.bias   torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for key in state_dict.keys():\n",
    "    print(\"{}. {}   {}\".format(count,key,state_dict[key].shape))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. conv1.0.weight,      torch.Size([64, 3, 3, 3])\n",
      "1. conv1.0.bias,      torch.Size([64])\n",
      "2. conv1.1.weight,      torch.Size([64])\n",
      "3. conv1.1.bias,      torch.Size([64])\n",
      "4. conv1.1.running_mean,      torch.Size([64])\n",
      "5. conv1.1.running_var,      torch.Size([64])\n",
      "6. conv1.1.num_batches_tracked,      torch.Size([])\n",
      "7. conv1.3.weight,      torch.Size([64, 64, 3, 3])\n",
      "8. conv1.3.bias,      torch.Size([64])\n",
      "9. pool1.0.weight,      torch.Size([64])\n",
      "10. pool1.0.bias,      torch.Size([64])\n",
      "11. pool1.0.running_mean,      torch.Size([64])\n",
      "12. pool1.0.running_var,      torch.Size([64])\n",
      "13. pool1.0.num_batches_tracked,      torch.Size([])\n",
      "14. conv2.0.weight,      torch.Size([128, 64, 3, 3])\n",
      "15. conv2.0.bias,      torch.Size([128])\n",
      "16. conv2.1.weight,      torch.Size([128])\n",
      "17. conv2.1.bias,      torch.Size([128])\n",
      "18. conv2.1.running_mean,      torch.Size([128])\n",
      "19. conv2.1.running_var,      torch.Size([128])\n",
      "20. conv2.1.num_batches_tracked,      torch.Size([])\n",
      "21. conv2.3.weight,      torch.Size([128, 128, 3, 3])\n",
      "22. conv2.3.bias,      torch.Size([128])\n",
      "23. pool2.0.weight,      torch.Size([128])\n",
      "24. pool2.0.bias,      torch.Size([128])\n",
      "25. pool2.0.running_mean,      torch.Size([128])\n",
      "26. pool2.0.running_var,      torch.Size([128])\n",
      "27. pool2.0.num_batches_tracked,      torch.Size([])\n",
      "28. conv3.0.weight,      torch.Size([256, 128, 3, 3])\n",
      "29. conv3.0.bias,      torch.Size([256])\n",
      "30. conv3.1.weight,      torch.Size([256])\n",
      "31. conv3.1.bias,      torch.Size([256])\n",
      "32. conv3.1.running_mean,      torch.Size([256])\n",
      "33. conv3.1.running_var,      torch.Size([256])\n",
      "34. conv3.1.num_batches_tracked,      torch.Size([])\n",
      "35. conv3.3.weight,      torch.Size([256, 256, 3, 3])\n",
      "36. conv3.3.bias,      torch.Size([256])\n",
      "37. pool3.0.weight,      torch.Size([256])\n",
      "38. pool3.0.bias,      torch.Size([256])\n",
      "39. pool3.0.running_mean,      torch.Size([256])\n",
      "40. pool3.0.running_var,      torch.Size([256])\n",
      "41. pool3.0.num_batches_tracked,      torch.Size([])\n",
      "42. conv4.0.weight,      torch.Size([512, 256, 3, 3])\n",
      "43. conv4.0.bias,      torch.Size([512])\n",
      "44. conv4.1.weight,      torch.Size([512])\n",
      "45. conv4.1.bias,      torch.Size([512])\n",
      "46. conv4.1.running_mean,      torch.Size([512])\n",
      "47. conv4.1.running_var,      torch.Size([512])\n",
      "48. conv4.1.num_batches_tracked,      torch.Size([])\n",
      "49. conv4.3.weight,      torch.Size([512, 512, 3, 3])\n",
      "50. conv4.3.bias,      torch.Size([512])\n",
      "51. pool4.0.weight,      torch.Size([512])\n",
      "52. pool4.0.bias,      torch.Size([512])\n",
      "53. pool4.0.running_mean,      torch.Size([512])\n",
      "54. pool4.0.running_var,      torch.Size([512])\n",
      "55. pool4.0.num_batches_tracked,      torch.Size([])\n",
      "56. conv5.0.weight,      torch.Size([512, 512, 3, 3])\n",
      "57. conv5.0.bias,      torch.Size([512])\n",
      "58. conv5.1.weight,      torch.Size([512])\n",
      "59. conv5.1.bias,      torch.Size([512])\n",
      "60. conv5.1.running_mean,      torch.Size([512])\n",
      "61. conv5.1.running_var,      torch.Size([512])\n",
      "62. conv5.1.num_batches_tracked,      torch.Size([])\n",
      "63. conv5.3.weight,      torch.Size([512, 512, 3, 3])\n",
      "64. conv5.3.bias,      torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "first_x_keys = list(state_dict.keys())[:86]\n",
    "\n",
    "extracted_dict = {key: state_dict[key] for key in first_x_keys if not any([\"conv3.4\" in key,\"conv3.6\" in key, \"conv4.4\" in key,\"conv4.6\" in key, \"conv5.4\" in key,\"conv5.6\" in key])}\n",
    "count=0\n",
    "for key in extracted_dict.keys():\n",
    "    print(\"{}. {},      {}\".format(count,key,state_dict[key].shape))\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['conv1.2.weight', 'conv1.2.bias', 'conv2.2.weight', 'conv2.2.bias', 'conv3.2.weight', 'conv3.2.bias', 'conv4.2.weight', 'conv4.2.bias', 'conv5.2.weight', 'conv5.2.bias'], unexpected_keys=['conv1.3.weight', 'conv1.3.bias', 'conv1.1.weight', 'conv1.1.bias', 'conv1.1.running_mean', 'conv1.1.running_var', 'conv1.1.num_batches_tracked', 'pool1.0.weight', 'pool1.0.bias', 'pool1.0.running_mean', 'pool1.0.running_var', 'pool1.0.num_batches_tracked', 'conv2.3.weight', 'conv2.3.bias', 'conv2.1.weight', 'conv2.1.bias', 'conv2.1.running_mean', 'conv2.1.running_var', 'conv2.1.num_batches_tracked', 'pool2.0.weight', 'pool2.0.bias', 'pool2.0.running_mean', 'pool2.0.running_var', 'pool2.0.num_batches_tracked', 'conv3.3.weight', 'conv3.3.bias', 'conv3.1.weight', 'conv3.1.bias', 'conv3.1.running_mean', 'conv3.1.running_var', 'conv3.1.num_batches_tracked', 'pool3.0.weight', 'pool3.0.bias', 'pool3.0.running_mean', 'pool3.0.running_var', 'pool3.0.num_batches_tracked', 'conv4.3.weight', 'conv4.3.bias', 'conv4.1.weight', 'conv4.1.bias', 'conv4.1.running_mean', 'conv4.1.running_var', 'conv4.1.num_batches_tracked', 'pool4.0.weight', 'pool4.0.bias', 'pool4.0.running_mean', 'pool4.0.running_var', 'pool4.0.num_batches_tracked', 'conv5.3.weight', 'conv5.3.bias', 'conv5.1.weight', 'conv5.1.bias', 'conv5.1.running_mean', 'conv5.1.running_var', 'conv5.1.num_batches_tracked'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(extracted_dict, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already working: Load entire dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LabVGG16:\n\tMissing key(s) in state_dict: \"conv1.2.weight\", \"conv1.2.bias\", \"conv2.2.weight\", \"conv2.2.bias\". \n\tUnexpected key(s) in state_dict: \"conv3.0.weight\", \"conv3.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.1.num_batches_tracked\", \"conv3.3.weight\", \"conv3.3.bias\", \"conv3.4.weight\", \"conv3.4.bias\", \"conv3.4.running_mean\", \"conv3.4.running_var\", \"conv3.4.num_batches_tracked\", \"conv3.6.weight\", \"conv3.6.bias\", \"pool3.0.weight\", \"pool3.0.bias\", \"pool3.0.running_mean\", \"pool3.0.running_var\", \"pool3.0.num_batches_tracked\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv4.1.weight\", \"conv4.1.bias\", \"conv4.1.running_mean\", \"conv4.1.running_var\", \"conv4.1.num_batches_tracked\", \"conv4.3.weight\", \"conv4.3.bias\", \"conv4.4.weight\", \"conv4.4.bias\", \"conv4.4.running_mean\", \"conv4.4.running_var\", \"conv4.4.num_batches_tracked\", \"conv4.6.weight\", \"conv4.6.bias\", \"pool4.0.weight\", \"pool4.0.bias\", \"pool4.0.running_mean\", \"pool4.0.running_var\", \"pool4.0.num_batches_tracked\", \"conv5.0.weight\", \"conv5.0.bias\", \"conv5.1.weight\", \"conv5.1.bias\", \"conv5.1.running_mean\", \"conv5.1.running_var\", \"conv5.1.num_batches_tracked\", \"conv5.3.weight\", \"conv5.3.bias\", \"conv5.4.weight\", \"conv5.4.bias\", \"conv5.4.running_mean\", \"conv5.4.running_var\", \"conv5.4.num_batches_tracked\", \"conv5.6.weight\", \"conv5.6.bias\", \"pool5.0.weight\", \"pool5.0.bias\", \"pool5.0.running_mean\", \"pool5.0.running_var\", \"pool5.0.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\", \"classifier.6.weight\", \"classifier.6.bias\", \"conv1.3.weight\", \"conv1.3.bias\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv1.1.num_batches_tracked\", \"pool1.0.weight\", \"pool1.0.bias\", \"pool1.0.running_mean\", \"pool1.0.running_var\", \"pool1.0.num_batches_tracked\", \"conv2.3.weight\", \"conv2.3.bias\", \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\", \"conv2.1.num_batches_tracked\", \"pool2.0.weight\", \"pool2.0.bias\", \"pool2.0.running_mean\", \"pool2.0.running_var\", \"pool2.0.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# To load entire state dictionary\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./../model/LabVGG16_dict.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LabVGG16:\n\tMissing key(s) in state_dict: \"conv1.2.weight\", \"conv1.2.bias\", \"conv2.2.weight\", \"conv2.2.bias\". \n\tUnexpected key(s) in state_dict: \"conv3.0.weight\", \"conv3.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.1.num_batches_tracked\", \"conv3.3.weight\", \"conv3.3.bias\", \"conv3.4.weight\", \"conv3.4.bias\", \"conv3.4.running_mean\", \"conv3.4.running_var\", \"conv3.4.num_batches_tracked\", \"conv3.6.weight\", \"conv3.6.bias\", \"pool3.0.weight\", \"pool3.0.bias\", \"pool3.0.running_mean\", \"pool3.0.running_var\", \"pool3.0.num_batches_tracked\", \"conv4.0.weight\", \"conv4.0.bias\", \"conv4.1.weight\", \"conv4.1.bias\", \"conv4.1.running_mean\", \"conv4.1.running_var\", \"conv4.1.num_batches_tracked\", \"conv4.3.weight\", \"conv4.3.bias\", \"conv4.4.weight\", \"conv4.4.bias\", \"conv4.4.running_mean\", \"conv4.4.running_var\", \"conv4.4.num_batches_tracked\", \"conv4.6.weight\", \"conv4.6.bias\", \"pool4.0.weight\", \"pool4.0.bias\", \"pool4.0.running_mean\", \"pool4.0.running_var\", \"pool4.0.num_batches_tracked\", \"conv5.0.weight\", \"conv5.0.bias\", \"conv5.1.weight\", \"conv5.1.bias\", \"conv5.1.running_mean\", \"conv5.1.running_var\", \"conv5.1.num_batches_tracked\", \"conv5.3.weight\", \"conv5.3.bias\", \"conv5.4.weight\", \"conv5.4.bias\", \"conv5.4.running_mean\", \"conv5.4.running_var\", \"conv5.4.num_batches_tracked\", \"conv5.6.weight\", \"conv5.6.bias\", \"pool5.0.weight\", \"pool5.0.bias\", \"pool5.0.running_mean\", \"pool5.0.running_var\", \"pool5.0.num_batches_tracked\", \"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\", \"classifier.6.weight\", \"classifier.6.bias\", \"conv1.3.weight\", \"conv1.3.bias\", \"conv1.1.weight\", \"conv1.1.bias\", \"conv1.1.running_mean\", \"conv1.1.running_var\", \"conv1.1.num_batches_tracked\", \"pool1.0.weight\", \"pool1.0.bias\", \"pool1.0.running_mean\", \"pool1.0.running_var\", \"pool1.0.num_batches_tracked\", \"conv2.3.weight\", \"conv2.3.bias\", \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\", \"conv2.1.num_batches_tracked\", \"pool2.0.weight\", \"pool2.0.bias\", \"pool2.0.running_mean\", \"pool2.0.running_var\", \"pool2.0.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "# To load entire state dictionary\n",
    "net.load_state_dict(torch.load(\"./../model/LabVGG16_dict.pth\",map_location=torch.device('cpu')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
